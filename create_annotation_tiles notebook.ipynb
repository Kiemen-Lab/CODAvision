{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T21:07:20.344317Z",
     "start_time": "2024-05-21T21:07:20.338317Z"
    }
   },
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "from combine_annotations_into_tiles import combine_annotations_into_tiles\n",
    "import os\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:07:31.840874Z",
     "start_time": "2024-05-21T21:07:31.600876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pre - inputs\n",
    "pth = r'\\\\10.99.68.52\\Kiemendata\\Valentina Matos\\coda to python\\test model'\n",
    "pthim_ann = r'\\\\10.99.68.52\\Kiemendata\\Valentina Matos\\coda to python\\test model\\5x'\n",
    "classcheck = 0\n",
    "\n",
    "\n",
    "from load_annotation_data import load_annotation_data\n",
    "# _____________________________________________________________________________\n",
    "\n",
    "# Inputs\n",
    "pthDL = r'\\\\10.99.68.52\\Kiemendata\\Valentina Matos\\coda to python\\test model\\04_19_2024'\n",
    "ctlist0, numann0 = load_annotation_data(pthDL, pth, pthim_ann, classcheck)\n"
   ],
   "id": "6cae1d945ebfe561",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Importing annotation data...\n",
      "Image 1 of 2: SG_013_0061\n",
      " annotation data previously loaded\n",
      "Image 2 of 2: SG_014_0016\n",
      " annotation data previously loaded\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:07:37.922881Z",
     "start_time": "2024-05-21T21:07:37.908884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Function\n",
    "# ______________________________________________________________________________"
   ],
   "id": "8e3074d3d4f4bed7",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:07:41.593769Z",
     "start_time": "2024-05-21T21:07:41.580769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data from net.pkl file\n",
    "with open(os.path.join(pthDL, 'net.pkl'), 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    sxy, nblack, classNames, ntrain, nvalidate = data['sxy'], data['nblack'], data['classNames'], data['ntrain'], data['nvalidate']\n"
   ],
   "id": "2f47a5d447a3cd23",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:07:45.360192Z",
     "start_time": "2024-05-21T21:07:45.346193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if classNames[-1] == \"black\":\n",
    "    classNames = classNames[:-1]\n",
    "print('')"
   ],
   "id": "aa3950bf6ddc72bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:08:21.761752Z",
     "start_time": "2024-05-21T21:08:21.744752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Calculating total number of pixels in the training dataset...')\n",
    "count_annotations = sum(numann0)\n",
    "annotation_composition = count_annotations / max(count_annotations) * 100\n",
    "for b, count in enumerate(annotation_composition):\n",
    "    if annotation_composition[b] == 100:\n",
    "        print(f' There are {count} pixels of {classNames[b]}. This is the most common class.')\n",
    "    else:\n",
    "        print(f' There are {count} pixels of {classNames[b]}, {int(annotation_composition[b])}% of the most common class.')\n"
   ],
   "id": "245b6f0fa4c9eb8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating total number of pixels in the training dataset...\n",
      " There are 19.905351465001388 pixels of islet, 19% of the most common class.\n",
      " There are 8.1496239311231 pixels of epithelium, 8% of the most common class.\n",
      " There are 13.580334757804946 pixels of vasculature, 13% of the most common class.\n",
      " There are 38.320937221401394 pixels of fat, 38% of the most common class.\n",
      " There are 17.82459048185089 pixels of acini, 17% of the most common class.\n",
      " There are 100.0 pixels of stroma. This is the most common class.\n",
      " There are 87.00521934212013 pixels of nontissue, 87% of the most common class.\n",
      " There are 35.270251982192015 pixels of PanIN, 35% of the most common class.\n",
      " There are 10.700279174113403 pixels of nerves, 10% of the most common class.\n",
      " There are 37.76189140810624 pixels of immune, 37% of the most common class.\n",
      " There are 9.900705538976249 pixels of PDAC, 9% of the most common class.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:08:27.965462Z",
     "start_time": "2024-05-21T21:08:27.952464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for missing annotations\n",
    "if 0 in count_annotations:\n",
    "    raise ValueError('There are no annotations for one or more classes. Please add annotations, check nesting, or remove empty classes.')\n"
   ],
   "id": "e3fb524706d61efc",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:11:30.818036Z",
     "start_time": "2024-05-21T21:11:30.444036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build training tiles\n",
    "print('')\n",
    "print('Building training tiles...')\n",
    "numann0 = np.array(numann0)  # Convert numann0 to a NumPy array\n",
    "numann = numann0.copy()\n",
    "percann = np.double(numann0 > 0)\n",
    "percann0 = percann.copy()\n",
    "ty = 'training\\\\'\n",
    "obg = os.path.join(pthDL, ty, 'big_tiles\\\\')\n",
    "# Generate tiles until enough are made\n",
    "train_start = time.time()\n",
    "if len(glob.glob(os.path.join(obg, 'HE*.jpg'))) >= ntrain:\n",
    "    print('  Already done.')\n",
    "else:\n",
    "    while len(glob.glob(os.path.join(obg, 'HE*.jpg'))) < ntrain:\n",
    "        numann, percann = combine_annotations_into_tiles(numann0, numann, percann, ctlist0, nblack, pthDL, ty, sxy)\n",
    "        elapsed_time = time.time() - train_start\n",
    "        print(f'  {len(glob.glob(os.path.join(obg, \"HE*.jpg\")))} of {ntrain} training images completed in {int(elapsed_time / 60)} minutes')\n",
    "\n",
    "        baseclass1 = np.sum(percann0[:, :, 0])\n",
    "        usedclass1 = np.sum(percann[:, :, 0])\n",
    "        baseclass2 = np.sum(percann0[:, :, 1] == 1)\n",
    "        usedclass2 = np.sum(percann[:, :, 1] == 2)\n",
    "\n",
    "        tmp1 = usedclass1 / baseclass1 * 100\n",
    "        tmp2 = usedclass2 / baseclass2 * 100\n",
    "\n",
    "        for b, class_name in enumerate(classNames):\n",
    "            print(f'  Used {tmp1[b]:.1f}% counts and {tmp2[b]:.1f}% unique annotations of {class_name}')\n",
    "            \n",
    "total_time_train_bigtiles = time.time() - train_start\n",
    "hours, rem = divmod(total_time_train_bigtiles, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(f'  Elapsed time to create training big tiles: {hours}h {minutes}m {seconds}s')\n",
    "\n",
    "print('')"
   ],
   "id": "998bf000c2cca0c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building training tiles...\n",
      "Starting time for the while loop\n",
      "Iteration: 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(glob\u001B[38;5;241m.\u001B[39mglob(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(obg, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHE*.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m))) \u001B[38;5;241m<\u001B[39m ntrain:\n\u001B[1;32m---> 16\u001B[0m         numann, percann \u001B[38;5;241m=\u001B[39m \u001B[43mcombine_annotations_into_tiles\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumann0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumann\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpercann\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctlist0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnblack\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpthDL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mty\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msxy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m         elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m train_start\n\u001B[0;32m     18\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(glob\u001B[38;5;241m.\u001B[39mglob(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(obg,\u001B[38;5;250m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHE*.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)))\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mntrain\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m training images completed in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mint\u001B[39m(elapsed_time\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m60\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m minutes\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\CODA_python\\combine_annotations_into_tiles.py:109\u001B[0m, in \u001B[0;36mcombine_annotations_into_tiles\u001B[1;34m(numann0, numann, percann, imlist, nblack, pthDL, outpth, sxy, stile, nbg)\u001B[0m\n\u001B[0;32m    107\u001B[0m doaug \u001B[38;5;241m=\u001B[39m (count \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    108\u001B[0m im, TA, kp \u001B[38;5;241m=\u001B[39m edit_annotations_tiles(im, TA, doaug, type_, ct, imT\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], kpall)\n\u001B[1;32m--> 109\u001B[0m numann[num, kp \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m  \u001B[38;5;66;03m# kp-1 due to layer index starting in 1 and python index starting in 0\u001B[39;00m\n\u001B[0;32m    110\u001B[0m percann[num, kp \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    111\u001B[0m percann[num, kp \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n",
      "\u001B[1;31mIndexError\u001B[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Build validation tiles\n",
    "\n",
    "ty = 'validation\\\\'\n",
    "obg = os.path.join(pthDL, ty, 'big_tiles\\\\')\n",
    "numann = numann0.copy()\n",
    "percann = (numann0 > 0).astype(float)\n",
    "percann = np.dstack((percann, percann))\n",
    "percann0 = percann.copy()\n",
    "validation_start_time = time.time()\n",
    "\n",
    "print('')\n",
    "print('Building validation tiles...')\n",
    "if len(glob.glob(os.path.join(obg, 'HE*.jpg'))) >= nvalidate:\n",
    "    print('Already done.')\n",
    "else:\n",
    "    while len(glob.glob(os.path.join(obg, 'HE*.jpg'))) < nvalidate:\n",
    "        numann, percann = combine_annotations_into_tiles(numann0, numann, percann, ctlist0, nblack, pthDL, ty, sxy)\n",
    "        elapsed_time = time.time() - validation_start_time\n",
    "        print(f'{len(glob.glob(os.path.join(obg, \"HE*.jpg\")))} of {nvalidate} validation images completed in {int(elapsed_time / 60)} minutes')\n",
    "\n",
    "        baseclass1 = np.sum(percann0[:, :, 0])\n",
    "        usedclass1 = np.sum(percann[:, :, 0])\n",
    "        baseclass2 = np.sum(percann0[:, :, 1] == 1)\n",
    "        usedclass2 = np.sum(percann[:, :, 1] == 2)\n",
    "\n",
    "        tmp1 = usedclass1 / baseclass1 * 100\n",
    "        tmp2 = usedclass2 / baseclass2 * 100\n",
    "\n",
    "        for b, class_name in enumerate(classNames):\n",
    "            print(f'Used {tmp1[b]:.1f}% counts and {tmp2[b]:.1f}% unique annotations of {class_name}')\n",
    "            \n",
    "total_time_validation_bigtiles = time.time() - validation_start_time\n",
    "hours, rem = divmod(total_time_validation_bigtiles, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(f'Elapsed time to create validation big tiles: {hours}h {minutes}m {seconds}s')\n"
   ],
   "id": "3528c2f298dd9ca5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1592079e1990f0cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
