{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import shutil\n",
    "import pickle\n",
    "from base import *\n",
    "from CODAGUI_fend import MainWindow\n",
    "import sys\n",
    "from PySide6 import QtWidgets\n",
    "from classify_im_fend import MainWindowClassify\n",
    "\n",
    "# 1 Execute the GUI\n",
    "app = QtWidgets.QApplication.instance()\n",
    "if app is None:\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "\n",
    "# Load and apply the dark theme stylesheet\n",
    "with open('dark_theme.qss', 'r') as file:\n",
    "    app.setStyleSheet(file.read())\n",
    "\n",
    "window = MainWindow()\n",
    "window.show()\n",
    "app.exec()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if window.classify:\n",
    "    if window.classification_source == 1:\n",
    "        with open(window.pth_net, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            pthim = data['pthim']\n",
    "            umpix = data['umpix']\n",
    "            nm = data['nm']\n",
    "            final_df = data['final_df']\n",
    "            model_type = data['model_type']\n",
    "        umpix_to_resolution = {1: '10x', 2: '5x', 4: '1x'}\n",
    "        resolution = umpix_to_resolution[umpix]\n",
    "        pth = ''\n",
    "        for element in pthim.split(os.sep)[:-1]:\n",
    "            pth = os.path.join(pth, element)\n",
    "        window2 = MainWindowClassify(pth, resolution, nm, model_type)\n",
    "        window2.show()\n",
    "        app.exec()\n",
    "    else:\n",
    "        window2 = MainWindowClassify(window.pthim, window.resolution, window.nm, window.model_type)\n",
    "        window2.show()\n",
    "        app.exec()\n",
    "else:\n",
    "    # Load the paths from the GUI\n",
    "    pth = os.path.abspath(window.ui.trianing_LE.text())\n",
    "    pthDL = os.path.abspath(window.get_pthDL())\n",
    "    pthim = os.path.abspath(window.get_pthim())\n",
    "    pthtest = os.path.abspath(window.ui.testing_LE.text())\n",
    "    pthtestim = os.path.abspath(window.get_pthtestim())\n",
    "    nTA = window.TA\n",
    "    umpix = window.umpix\n",
    "    resolution = window.resolution\n",
    "    model_type = window.model_type"
   ],
   "id": "fcb6baa5119a73fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### From this point on, we assume the user did not choose to classify images but to train a new model\n",
    "# Create tiff images if they don't exist\n",
    "print(' ')\n",
    "WSI2tif(pth, resolution, umpix)"
   ],
   "id": "fe17908d70969d96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Determine optimal TA\n",
    "determine_optimal_TA(pthim, nTA)"
   ],
   "id": "767aa67dbd1c7c7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2 load and format annotations from each annotated image\n",
    "[ctlist0, numann0, create_new_tiles] = load_annotation_data(pthDL, pth, pthim)"
   ],
   "id": "d6fa2f1c807b9d39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3 Make training & validation tiles for model training\n",
    "create_training_tiles(pthDL, numann0, ctlist0, create_new_tiles)"
   ],
   "id": "871e506589c04b53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4 Train model\n",
    "train_segmentation_model_cnns(pthDL)"
   ],
   "id": "c4afd5abbd2e35f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 5 Test model\n",
    "print(' ')\n",
    "WSI2tif(pthtest, resolution, umpix)\n",
    "if not os.path.isfile(os.path.join(pthtest,resolution,'TA','TA_cutoff.pkl')):\n",
    "    try:\n",
    "        os.makedirs(os.path.join(pthtest,resolution,'TA'), exist_ok=True)\n",
    "        shutil.copy(os.path.join(pthim,'TA','TA_cutoff.pkl'),os.path.join(pthtest,resolution,'TA','TA_cutoff.pkl'))\n",
    "    except:\n",
    "        print('No TA cutoff file found, using default value')\n",
    "test_segmentation_model(pthDL, pthtest, pthtestim)"
   ],
   "id": "cd417bbdc73a33c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 6 Classify images with pretrained model\n",
    "classify_images(pthim, pthDL, model_type)"
   ],
   "id": "1864ce34b7ff5ef5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 7 Quantify images\n",
    "quantify_images(pthDL, pthim)"
   ],
   "id": "fbeddb926a7c4e2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 8 Object count analysis if annotation classes were selected\n",
    "pickle_path = os.path.join(pthDL, 'net.pkl')\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "final_df = data['final_df']\n",
    "model_name = data['nm']\n",
    "classNames = data['classNames']\n",
    "quantpath = os.path.join(pthim, 'classification_'+model_name+'_'+model_type)\n",
    "\n",
    "# Identify annotation classes for component analysis\n",
    "tissues = []\n",
    "count = 0\n",
    "print(final_df)\n",
    "for index, row in final_df.iterrows():\n",
    "    if final_df['Delete layer'][index]:\n",
    "        count += 1\n",
    "    if row['Component analysis']:\n",
    "        tissues.append(final_df['Combined layers'][index]-count)\n",
    "tissues = list(set(tissues))\n",
    "\n",
    "# Check if the tissue list has elements\n",
    "for tissue in tissues:\n",
    "    if not os.path.isfile(os.path.join(quantpath, classNames[tissue-1]+'_count_analysis.csv')):\n",
    "        # Call the quantify_objects function\n",
    "        quantify_objects(pthDL, quantpath, tissue)\n",
    "    else:\n",
    "        print(f'Object quantification already done for {classNames[tissue-1]}')"
   ],
   "id": "e6b29993b5210300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "output_path = os.path.join(pthDL, model_type+ 'evaluation_report.pdf')\n",
    "confusion_matrix_path = os.path.join(pthDL, 'confusion_matrix_'+model_type+'.jpg')\n",
    "color_legend_path = os.path.join(pthDL, 'model_color_legend.jpg')\n",
    "check_annotations_path = os.path.join(pth, 'check_annotations')\n",
    "check_quant = os.path.join(quantpath, 'image_quantifications.csv')\n",
    "check_classification_path = os.path.join(pth, resolution,'classification_'+model_name+'_'+model_type, 'check_classification')\n",
    "create_output_pdf(output_path, pthDL, confusion_matrix_path, color_legend_path, check_annotations_path,\n",
    "                      check_classification_path, check_quant)"
   ],
   "id": "ada559eda1a066b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
